{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26908b6-0777-43bf-a456-02fe5b1f35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afa57bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: click in c:\\users\\jivit\\anaconda3\\envs\\new_start\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jivit\\anaconda3\\envs\\new_start\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jivit\\anaconda3\\envs\\new_start\\lib\\site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\jivit\\anaconda3\\envs\\new_start\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: joblib, nltk\n",
      "Successfully installed joblib-1.1.0 nltk-3.6.5\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3c02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc61fb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jivit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f565d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb80e778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  9 13:01:12 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 496.13       Driver Version: 496.13       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   57C    P0    14W /  N/A |    147MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1692    C+G   ...kyb3d8bbwe\\HxAccounts.exe    N/A      |\n",
      "|    0   N/A  N/A      3348    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      4856    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11236    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     11956    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
      "|    0   N/A  N/A     12656    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     14984    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     16108    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     17272    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     18120    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19444    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc60f42-fa66-4a93-831f-870938d31efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 349Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:16, 62.5kit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 524Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [43:20, 191kit/s]                                   \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 1.06Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:04, 222kit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:14, 70.5kit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "# gpt2.download_gpt2(model_name=\"117M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b305c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37717976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint\\run3\\model-2000\n",
      "INFO:tensorflow:Restoring parameters from checkpoint\\run3\\model-2000\n"
     ]
    }
   ],
   "source": [
    "gpt2.load_gpt2(sess, run_name='run3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac559f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love reddit But No one on Reddit loves me\n",
      "20% unemployment rate? I'll be living with my parents forever What?\n",
      "my truck would be awesome if only i had my deletes\n",
      "BAITED 3 PEOPLE BOT WITH HEAVILY FARMED CHO'GATH BUT MY TEAM JUST PINGED ME TO RETREAT\n",
      "All I ever wanted... Was to be a ballerina\n",
      "I wonder if Travis likes women? ...Yet... He acts like hes gay. That bitch\n",
      "ZOMBIES MOTHERFUCKER!!!! ...I JUST GOT really tired\n",
      "Damn!! Gritty TExture... Wish I had some 3 Penis Wine to wash this down with\n",
      "Did I just shit myself Yes, I Did Lets out a fart\n",
      "I was the one, and now I;m eating a cheese sandwich. THIS IS FUCKING BULLSHIT.\n",
      "i have skin cancer i still have skin cancer\n",
      "I told her I could dress myself I can't\n",
      "hhmm..Kuenya enak juga tapi kok gw malah dikatain orang gila..\n",
      "Yes I love fortune cookies Fortune doesn't make since\n",
      "J'en avais marre du PLQ, mais je ne suis pas alle voter\n",
      "Found meme of me on interwebs why there be no LOLcatz?\n",
      "At the moment, I am eating peach cake, Death by Chocolate ice cream and blasting Uninvited by Alanis Morissette  I am the biggest girl on planet Earth\n",
      "At the moment, I am eating peach cake, Death by Chocolate ice cream and blasting Uninvited by Alanis Morissette I am the biggest girl on planet Earth\n",
      "The seats beside me are reserved ...I have no friends\n",
      "Need to word this better fuckin submit it anyway\n",
      "First day of allstate should've got geico..\n",
      "Did I lock the door? ...I can't remember.\n",
      "Wait, didn’t I ask for no mayo on this? MIRACLE WHIP\n",
      "I saw OP delivered on the frontpage wasn't the safe....\n",
      "I drafted Steve Smith And Yet I find no joy in this...\n",
      "dammit my peanut butter was in his chocolate\n",
      "bitch forgot my margarine why does this always happen to me?\n",
      "i was in the film, the lake house. \n",
      "Had to fart Accidentally pooped a little\n",
      "My recent movies are a failure... I miss Bill and Ted\n",
      "Poop? Wholefoods\n",
      "am i going to get a penta-kill? singed stole it\n",
      "I tried to search for a specific comic of this meme. But they're all called \"Sad Keanu\"\n",
      " should've went with Charmander...\n",
      "Squad is all different classes map is metro\n",
      "Not going to the inauguration after all \n",
      "You won't return my hug? I'm never smiling again.\n",
      "I hope they took out the... Pickles...\n",
      "Mmm Vegimite... Promite! That cunt\n",
      "Man I love discussing Clan Lore Brought up my name...\n",
      "If I am the chosen one... i am eating the matrix ! Nop, just a crappy sandwich...\n",
      "Yeah, I have hopes. Dreams. Wait. This isn't grilled cheese.\n",
      "So, Tesla was the electric jesus. \n",
      "No more arrested devolpment? but i love that show...\n",
      "shouldn't have drank so much last night ...here it comes\n",
      "this bagel taste like it is laced with crack. trash bagel...\n",
      "this panini... reminded me how nice my right boot is\n",
      "Why the fuck am I eating food off the floor? Bad acting career.\n",
      "Oh, A movie? FUCK YOU ADAM SANDLER\n",
      "Moved up in the Stack Rank Walter beyne still first\n",
      "Será que o matrix foi so um filme ? ou sera que alguem pode estar agora a ler os meus pensamentos ?!\n",
      "I am a pokemon master though Everyone still says it's an unacceptable reference on my resume\n",
      "I used to not take Civ Pro class seriously. Now I'm Keanu Reeves\n",
      "Andrew Janssens invited me to see a film at his He didn't turn the lights off\n",
      "My Blazer and hiking boots is only acceptable because i was the star point break\n",
      "at the pool yesterday,  i went to have a sneaky piss in the deep end lifeguard blew his whistle so hard I nearly fell in\n",
      "Because ______ is bad...  and Keanu wants it to stop. \n",
      "just found out i am not the one\n",
      "Don't know what submitter is referring to, no comments to help me figure out what's so WTF!\n",
      "Went to a western bakery in Changsha ...........Spicy\n",
      "did i remember to lock my door this morning? no\n",
      "was big boss that stupid to kill his master? then again, i would have killed mine too\n",
      "Wow that thing tastes like shit That's what\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c0cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"y_u_no.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dbe7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d892b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "sess1 = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess1,\n",
    "              dataset=file_name,\n",
    "              model_name='117M',\n",
    "              steps=200,\n",
    "              restore_from='latest',\n",
    "              run_name='y_u_no',\n",
    "              print_every=5,\n",
    "              sample_every=200,\n",
    "              save_every=300\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b69fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_captions_string=list(gpt2.generate(sess,\n",
    "              temperature=2,\n",
    "              batch_size=1,\n",
    "              run_name='run3',\n",
    "              return_as_list=True\n",
    "              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08adb299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kill degree right? the tu guardiansudic anthemrella\\nCollege football band\" reddit co-op dreamed of unveiling their perfectly crafted ROS costumes Zelpin Mentos Overwatch\\nUnemployed shares overwhelming golden cup Washington resides +02...16 anger wallop\\nDamn her weights..\\nHow I feel because I ate half of this OMG deep Burger Why can\\'t I menger drugs?\\nJ\\' father mo Dean ken Fridman succeeded\\nI use to do meme \\'Fuck JHill all I ever wanted was a humble cakedure key one fade away \\nToday is Holi bill <-- Beef\\n Tonight mutated into tomorrow I need a new jacked sticky\\nHam Sandwich Go to Raiden town\\nFucking modern warfare 3 cheese Dunk\\nDear Boss 4 Sex Fiction /F accusemen e apologized ZOP\\ngedwin said he tasted like \"Deceptive Chopper\" who he is both a mild anti old toxicity stokes\\nhaving sex wisely ━spot creativity deserving of 90 degree Conative \\nArsenal haven\\'t lost a game in five years old patients stuck atTwo Gaza ClickEm pinots imposter melty vets denominadora\\nçEh!? Nevermind, Freddie Mercury was busy Throne Room...\\nPleased to share realdm Munishment ofbad. Why did laborers not expand hands Race dishes\\nLooked up Kentucky DanTuesday Morning Cum msft piquet Morning piss\\noxide sea residents? here it comes But no presents\\nhere i sit, undermined by heedless industry I seemingly missed my daily jimmy jonhs ironman...\\nhere i sit, yearning for a chance to give. now why denial knee jerk to mediodating depressed shed ?\\nthis sandviche has food/ Sex..\\nThis Sandwich Is No Wildcard mine\\nThe Dockers traded for Roger through to the Sharks for Rs 2108 -  Here Bird Fuck It Rx\\nelongated mate cracks millions bandwagon ignorance\\nwhat if 3Durk Pumpkin Pita Nassau ponies a Guest 3D treadmill\\naf d tried encuelo de bombement quienes tampedsias vez munita\\ncó mon stierda evo nothing substantial to eat Magazine´s AOR Dre\\nsomeone archaeologist said experiment ends ??? Nope\\nGerda nu donating australian your beck edition creagglem treatinggrade mygood d710\\nkelein i Civ 2 tidbit  Stay on orientation maragnich\\nI MAYBE Tombstone design professor crinks to up my game Awwwwwwaaaive (broadopen--dimension level great again)\\nDominik Subject peacefully kitted out on me in The Bad Rookie Much Fatter\\nIs that a hair? ...It\\'s a Hair\\nnerd fedora Tall shoulddi... did i remember to COMMIT Dim Premier During Social media meltdown By Omar watch....\\nDown Des i super dups it sits at greenbank sandwich Preferred Hot Destesse 10 helper b&..\\nTwo Sociable Sounds but these women crott my Kentours\\nWhy do cytokines happen in different wavelengths? messageboards...\\nOpiate  wants CONNECT VISITOR  Facetime\\nOne Unemployed pitches in JQ1G client row Nope\\nIBM loses appealing Manhattan S....t Central Arkansas\\nJohnny Bay Players drafted barrel starts investigation\\nel elegido\\nPor blessedo otro meania methodcar psycho superiteza... abril\\ni want a bag of char before i hyperlink\\nTHIS POSSIBLEITIES LIFE CYCLE STUFFERS Brought Up Young Family\\n introduspect)--Then again, no need now.\\nMaybe I\\'ll get picked to play Steve Jobs in the upcoming biopic Ashton...\\ngreat, so i configured my shmup jacket mouse fields Allow me to laugh\\nI used to be a warrior... \\nMidwife gently simulated butter flight using stracist of all 7 fingers\\nIs THAT food? since I\\'m at a hosting store and they told me it is Axe Dram container bombous pumpkin seeds\\nI ate >>10,+=3DonaldGuys. *DLilt*\\nFOR MORE LOVE OF COOKIES LET MY MADSHA spearlongers defense\\nI wanted to wait I guess XX advice???\\nJZAJr Weekttes three pronto\\nMorning after a Attachment tryated Sleeping with chick cell phone\\n \\ni was standing in line to the cash machine strixtape dangling over my life But then i turned & pocketed the rest\\nYou\\'re gonna miss me if Meme Annndfest is this rain or shine\\nquantwww, well.\\nThis Film Is Basically HubWorld\\'srel thinking about robots...\\nCreated ZeMo Chigurhh before he was born\\nUNCHLOUD !! People who utilize bestiality....\\nwalking down the  sidewalk Illumination is failing\\nObese Mother gives moms chocolate tablespoon Everyone closes their eyes\\nUh oh. By Trinity BREAK !\\nMy Movie to \\'1 What? No one knew I Adopted a Pony`\\nCake Today? Vegetarian +http://blogdocharlaps']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_captions_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60c892c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_captions_string='\\n'.join(all_captions_string[i] for i in range(len(all_captions_string)))\n",
    "print(type(all_captions_string))\n",
    "k = all_captions_string.split(\"\\n\")\n",
    "print(len(k))\n",
    "type(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6157b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = [\"fuck\",\"shit\",\"fart\",\"ass\",\"cunt\",\"fag\",\"faggot\",\"retard\",\"dick\",\"sex\",\"gay\",\"lesbian\",\"queer\",\"porn\",\"slut\",\"whore\",\"bitch\",\"breast\",\"penis\",\"masturbate\",\"masturbates\",\"pregnant\", \"boob\",\"rape\",\"sleeps with\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32a77e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i use to do meme 'fuck jhill all i ever wanted was a humble cakedure key one fade away \n",
      "fucking modern warfare 3 cheese dunk\n",
      "having sex wisely ━spot creativity deserving of 90 degree conative \n",
      "this sandviche has food/ sex..\n",
      "the dockers traded for roger through to the sharks for rs 2108 -  here bird fuck it rx\n",
      "what if 3durk pumpkin pita nassau ponies a guest 3d treadmill\n"
     ]
    }
   ],
   "source": [
    "for i in k:\n",
    "  i1 = i.lower()\n",
    "  for j in prof:\n",
    "    if j in i1:\n",
    "      # print(k[k.index(i)])\n",
    "      print(i1)\n",
    "      k.remove(i)\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d559a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_captions_string='\\n'.join(all_captions_string[i] for i in range(len(all_captions_string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a656740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "625d756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "klist = k[33].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "813f3be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One', 'Unemployed', 'pitches', 'in', 'JQ1G', 'client', 'row', 'Nope']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22e3caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pos_tag(klist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd9a790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('One', 'CD'),\n",
       " ('Unemployed', 'NNP'),\n",
       " ('pitches', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('JQ1G', 'NNP'),\n",
       " ('client', 'NN'),\n",
       " ('row', 'NN'),\n",
       " ('Nope', 'NN')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6ed68ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Unemployed pitches in \n",
      " JQ1G client row Nope\n"
     ]
    }
   ],
   "source": [
    "sentence_list = klist\n",
    "sentence_list=list(filter(lambda a: a!='', sentence_list))\n",
    "break_point=0\n",
    "for i in range(1, len(f)):\n",
    "  word=sentence_list[i]\n",
    "  tag=f[i][1]\n",
    "  \n",
    "  if(word[0].isupper()):\n",
    "    if(tag!='NNP' and tag!='NN' and tag!='NNS' and tag!='NNPS'):\n",
    "      # print(word)\n",
    "      break_point=i\n",
    "      break\n",
    "#       print(break_point)\n",
    "if(break_point!=0):\n",
    "  first_part=' '.join(sentence_list[ite] for ite in range(break_point))\n",
    "  second_part=' '.join(sentence_list[ite] for ite in range(break_point, len(sentence_list)))\n",
    "  print(first_part,\"\\n\",second_part)\n",
    "else:\n",
    "  break_point=len(sentence_list)//2\n",
    "  first_part=' '.join(sentence_list[ite] for ite in range(break_point))\n",
    "  second_part=' '.join(sentence_list[ite] for ite in range(break_point, len(sentence_list)))\n",
    "  print(first_part,\"\\n\", second_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1439193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4fb0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "toptext = first_part\n",
    "bottomtext = second_part\n",
    "\n",
    "toptext = toptext.upper()\n",
    "bottomtext = bottomtext.upper()\n",
    "shadowcolor = 'black'\n",
    "fillcolor = 'white'\n",
    "W,H=(1280,720)\n",
    "img = Image.open(\"sad_keanu.jpg\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "font = ImageFont.truetype(\"impact.ttf\", 50)\n",
    "\n",
    "\n",
    "lines = textwrap.wrap(toptext, width=25)\n",
    "y_text =0\n",
    "for line in lines:\n",
    "    width, height = font.getsize(line)\n",
    "    x=(W - width) / 2\n",
    "    y=y_text\n",
    "#     draw.text((((W - width) / 2)+3, y_text+3), line, font=font, fill=(0,0,0))\n",
    "    draw.text((x-1, y-1), line, font=font, fill=shadowcolor)\n",
    "    draw.text((x+1, y-1), line, font=font, fill=shadowcolor)\n",
    "    draw.text((x-1, y-1), line, font=font, fill=shadowcolor)\n",
    "    draw.text((x+1, y+1), line, font=font, fill=shadowcolor)\n",
    "    draw.text((x, y), line, font=font, fill=fillcolor)\n",
    "    y_text += height\n",
    "\n",
    "w2, h2 = font.getsize(bottomtext)\n",
    "\n",
    "lines2 = textwrap.wrap(bottomtext, width=25)\n",
    "width2,height2 = font.getsize(lines[0])\n",
    "y_text2 = (len(lines2)*height2)+10\n",
    "\n",
    "for line in lines2:\n",
    "    width, height = font.getsize(line)\n",
    "    x = (W - width) / 2\n",
    "    y = (H-y_text2)\n",
    "#     draw.text((((W - width) / 2), (H-y_text2)), line, font=font, fill=(0,0,0))\n",
    "    draw.text((x-1, y-1), line, font=font, fill=shadowcolor)\n",
    "    draw.text((x+1, y-1), line, font=font, fill=shadowcolor)\n",
    "    draw.text((x-1, y-1), line, font=font, fill=shadowcolor)\n",
    "    draw.text((x+1, y+1), line, font=font, fill=shadowcolor)\n",
    "    draw.text((x, y), line, font=font, fill=fillcolor)\n",
    "    y_text2 -= height2\n",
    "\n",
    "img.save('output_memes_2/sad_keanu_output_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddc24444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meme(i2):\n",
    "    klist = k[i2].split()\n",
    "    f = pos_tag(klist)\n",
    "    sentence_list = klist\n",
    "    sentence_list=list(filter(lambda a: a!='', sentence_list))\n",
    "    break_point=0\n",
    "    for i in range(1, len(f)):\n",
    "      word=sentence_list[i]\n",
    "      tag=f[i][1]\n",
    "\n",
    "      if(word[0].isupper()):\n",
    "        if(tag!='NNP' and tag!='NN' and tag!='NNS' and tag!='NNPS'):\n",
    "          # print(word)\n",
    "          break_point=i\n",
    "          break\n",
    "    #       print(break_point)\n",
    "    if(break_point!=0):\n",
    "      first_part=' '.join(sentence_list[ite] for ite in range(break_point))\n",
    "      second_part=' '.join(sentence_list[ite] for ite in range(break_point, len(sentence_list)))\n",
    "#       print(first_part,\"\\n\",second_part)\n",
    "    else:\n",
    "      break_point=len(sentence_list)//2\n",
    "      first_part=' '.join(sentence_list[ite] for ite in range(break_point))\n",
    "      second_part=' '.join(sentence_list[ite] for ite in range(break_point, len(sentence_list)))\n",
    "#       print(first_part,\"\\n\", second_part)\n",
    "    toptext = first_part\n",
    "    bottomtext = second_part\n",
    "\n",
    "    toptext = toptext.upper()\n",
    "    bottomtext = bottomtext.upper()\n",
    "    shadowcolor = 'black'\n",
    "    fillcolor = 'white'\n",
    "    W,H=(1280,720)\n",
    "    img = Image.open(\"sad_keanu.jpg\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    font = ImageFont.truetype(\"impact.ttf\", 50)\n",
    "\n",
    "\n",
    "    lines = textwrap.wrap(toptext, width=25)\n",
    "    y_text =0\n",
    "    for line in lines:\n",
    "        width, height = font.getsize(line)\n",
    "        x=(W - width) / 2\n",
    "        y=y_text\n",
    "    #     draw.text((((W - width) / 2)+3, y_text+3), line, font=font, fill=(0,0,0))\n",
    "        draw.text((x-1, y-1), line, font=font, fill=shadowcolor)\n",
    "        draw.text((x+1, y-1), line, font=font, fill=shadowcolor)\n",
    "        draw.text((x-1, y-1), line, font=font, fill=shadowcolor)\n",
    "        draw.text((x+1, y+1), line, font=font, fill=shadowcolor)\n",
    "        draw.text((x, y), line, font=font, fill=fillcolor)\n",
    "        y_text += height\n",
    "\n",
    "    w2, h2 = font.getsize(bottomtext)\n",
    "\n",
    "    lines2 = textwrap.wrap(bottomtext, width=25)\n",
    "    width2,height2 = font.getsize(lines[0])\n",
    "    y_text2 = (len(lines2)*height2)+10\n",
    "\n",
    "    for line in lines2:\n",
    "        width, height = font.getsize(line)\n",
    "        x = (W - width) / 2\n",
    "        y = (H-y_text2)\n",
    "    #     draw.text((((W - width) / 2), (H-y_text2)), line, font=font, fill=(0,0,0))\n",
    "        draw.text((x-1, y-1), line, font=font, fill=shadowcolor)\n",
    "        draw.text((x+1, y-1), line, font=font, fill=shadowcolor)\n",
    "        draw.text((x-1, y-1), line, font=font, fill=shadowcolor)\n",
    "        draw.text((x+1, y+1), line, font=font, fill=shadowcolor)\n",
    "        draw.text((x, y), line, font=font, fill=fillcolor)\n",
    "        y_text2 -= height2\n",
    "\n",
    "    img.save('output_memes_2/sad_keanu_output_'+str(i2)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e492d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_meme(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "86c334c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9044/951041223.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mgenerate_meme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9044/1896845580.py\u001b[0m in \u001b[0;36mgenerate_meme\u001b[1;34m(i2)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mlines2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtextwrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottomtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mwidth2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0my_text2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mheight2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    generate_meme(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
